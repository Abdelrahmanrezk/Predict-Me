{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04275171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "from scipy.stats import reciprocal\n",
    "import io\n",
    "import uvicorn\n",
    "import numpy as np\n",
    "import nest_asyncio\n",
    "from enum import Enum\n",
    "from fastapi import FastAPI, UploadFile, File, HTTPException\n",
    "from fastapi.responses import StreamingResponse\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Keras APIs\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras import models\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from configs import *\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fa13d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_images = images_pipeline(500, \"_500_500_3/\")\n",
    "X_train, X_val, y_train, y_val = load_train_validation_set(df_all_images)\n",
    "display_some_images(X_train, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b48acd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = X_train.T, X_val.T, y_train.T, y_val.T\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2297c83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[X_train.shape[1]]):\n",
    "    '''\n",
    "    The function used to help us searching for best hyper paramters using sklearn along with keras.\n",
    "    other optional parameters we can pass like metrics.\n",
    "\n",
    "    Argument:\n",
    "        n_hidden      : How many hidden layers we need\n",
    "        n_neurons     : For each hidden layer which number of neurons we need (fixed number for all hidden layers)\n",
    "        learning_rate : How to control the steps the model take during training\n",
    "        input_shape   : The number of features we have defined by the image (width * height * 3 for rgb)\n",
    "    \n",
    "    return:\n",
    "        model: The architecture of the model we have built and compiled \n",
    "    '''\n",
    "        \n",
    "     # Create the Sequential model\n",
    "    model = keras.models.Sequential()\n",
    "     # define the shape of the input layer from the features we have for each image\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    \n",
    "     # loop over hidden layers\n",
    "    for i in range(n_hidden):\n",
    "        \n",
    "        # for each hidden layer pass the number of neurons for this layer\n",
    "        model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
    "        \n",
    "    # at the end handle the output layer as we just need to predict image belong to me or not so its just one unit\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss=keras.losses.BinaryCrossentropy(),\n",
    "                  optimizer=keras.optimizers.SGD(lr=learning_rate), metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d563ba0",
   "metadata": {},
   "source": [
    "## First Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ab40ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_clf = keras.wrappers.scikit_learn.KerasClassifier(build_model)\n",
    "param_distribs = {\n",
    "     \"n_hidden\": [0, 1, 2, 3],\n",
    "     \"n_neurons\": np.arange(1, 100),\n",
    "     \"learning_rate\": reciprocal(3e-3, 2e0), # 3e-3 is 0.003 and 2e0 means 2.0\n",
    "}\n",
    "\n",
    "n_iter   = 2\n",
    "cv       = 2\n",
    "epochs   = 100\n",
    "patience = 10\n",
    "rnd_search_cv = RandomizedSearchCV(keras_clf, param_distribs, n_iter=n_iter, cv=cv)\n",
    "\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=epochs, validation_data=(X_val, y_val), \n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=patience)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9cae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383cf14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which size of images we train on and which keras api we use, and the overall(100*100*3) features of each image\n",
    "img_size      = \"img_size_500*500*3_\"\n",
    "api_type      = \"sequential_api_\"\n",
    "input_shape   = [X_train.shape[1]]\n",
    "\n",
    "#\n",
    "epochs         =  100\n",
    "patience       = 10\n",
    "\n",
    "# Retrieve the best hyper parameter\n",
    "learning_rate  =  rnd_search_cv.best_params_['learning_rate']\n",
    "n_hidden       =  rnd_search_cv.best_params_['n_hidden']\n",
    "n_neurons      =  rnd_search_cv.best_params_['n_neurons']\n",
    "\n",
    "\n",
    "model_hyper_params  = model_hyper_parameters(img_size, api_type, n_hidden, learning_rate, epochs)\n",
    "\n",
    "run_log_dir    = tensor_logs_dir(TENSOR_DIR, model_hyper_params)\n",
    "\n",
    "model_trained_path      = \"/run_with_\" + model_hyper_params +  \"_model.h5\"\n",
    "\n",
    "call_backs = call_backs(run_log_dir,model_trained_path, patience)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5160a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
